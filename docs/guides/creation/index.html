<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-guides/creation">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Using the Creation Tool | Eden</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://docs.eden.art/docs/guides/creation"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Using the Creation Tool | Eden"><meta data-rh="true" name="description" content="The easiest way to make creations with Eden is through the creation tool frontend."><meta data-rh="true" property="og:description" content="The easiest way to make creations with Eden is through the creation tool frontend."><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.eden.art/docs/guides/creation"><link data-rh="true" rel="alternate" href="https://docs.eden.art/docs/guides/creation" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.eden.art/docs/guides/creation" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.5e107846.css">
<link rel="preload" href="/assets/js/runtime~main.b6bbc6ef.js" as="script">
<link rel="preload" href="/assets/js/main.23358c95.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/eden.png" alt="Eden" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/eden.png" alt="Eden" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">Eden</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/category/overview">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://app.eden.art" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">App<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebar_njMd"><nav class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link" href="/docs/category/overview">Overview</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/intro">About Eden</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/manna">Manna</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/tos">Terms of Service</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/overview/privacy">Privacy policy</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--active" href="/docs/category/guides">Guides</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/guides/creation">Using the Creation Tool</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/guides/concepts">Training Concepts (LoRa)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/guides/agents">Creative AI Agents</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/guides/sdk">JavaScript SDK</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/guides/python-sdk">Python SDK</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/guides/generators">Custom hosted endpoints</a></li></ul></li></ul></nav></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Alpn" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/docs/category/overview"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_xK9p"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/guides"><span itemprop="name">Guides</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Using the Creation Tool</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Using the Creation Tool</h1><p>The easiest way to make creations with Eden is through the <a href="https://app.eden.art/create/creations" target="_blank" rel="noopener noreferrer">creation tool frontend</a>.</p><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_S0QG"><p>You can also interact with the creator tool <a href="/docs/guides/sdk">through the SDK</a>.</p></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a class="hash-link" href="#overview" title="Direct link to heading">​</a></h2><p>Eden offers a number of generative pipelines for making images and videos, mostly built on top of the <a href="https://stability.ai/stablediffusion" target="_blank" rel="noopener noreferrer">Stable Diffusion</a> model family. The pipelines are divided into a number of <em>endpoints</em> or <em>generators</em> (terms used interchangeably) which are optimized for different visual tasks.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary-of-endpoints">Summary of endpoints<a class="hash-link" href="#summary-of-endpoints" title="Direct link to heading">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="image-endpoints">Image endpoints<a class="hash-link" href="#image-endpoints" title="Direct link to heading">​</a></h4><ul><li><a href="#create"><strong>/create</strong></a> is our general-purpose text-to-image pipeline.</li><li><a href="#remix"><strong>/remix</strong></a> generates variations of an uploaded image.</li><li><a href="#blend"><strong>/blend</strong></a> generates a novel mixture of two uploaded images.</li><li><a href="#controlnet"><strong>/controlnet</strong></a> generates a prompt-guided style transfer over an uploaded image.</li><li><a href="#upscale"><strong>/upscale</strong></a> upscales a single image to a higher resolution.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="video-endpoints">Video endpoints<a class="hash-link" href="#video-endpoints" title="Direct link to heading">​</a></h4><ul><li><a href="#interpolate"><strong>/interpolate</strong></a> generates a video which gradually interpolates through a sequence of prompts.</li><li><a href="#real2real"><strong>/real2real</strong></a> generates a video which gradually interpolates through a sequence of uploaded images.</li><li><a href="#img2vid"><strong>/img2vid</strong></a> generates a video from a starting image (animating the image)</li><li><a href="#txt2vid"><strong>/txt2vid</strong></a> generates a video from a (list of) prompt(s)</li><li><a href="#vid2vid"><strong>/vid2vid</strong></a> apply style transfer to an input video</li></ul><p>Each of the endpoints are calibrated to give you good creations using the default settings, but achieving more particular or custom results requires some understanding of the optional parameters.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="create">/create<a class="hash-link" href="#create" title="Direct link to heading">​</a></h3><p><strong><a href="https://app.eden.art/create/creations" target="_blank" rel="noopener noreferrer">Create</a></strong> is our default <em>text-to-image</em> endpoint. Simply enter a prompt, click &quot;Create&quot; and wait a few moments for the resulting image.</p><p align="center"><img src="/img/create.jpg" alt="Creation tool interface"><br><small style="color:gray">Creation tool interface</small></p><p>Besides the prompt, you are able to request 1, 2, or 4 different samples. </p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="settings">Settings<a class="hash-link" href="#settings" title="Direct link to heading">​</a></h4><p>The &quot;Settings&quot; dropdown lists optional settings which can be used to customize your creation. It is always divided into commonly customized settings like the resolution, as well as <em>advanced</em> settings which should rarely need to be modified, but are available for further customization.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="common-settings">Common settings<a class="hash-link" href="#common-settings" title="Direct link to heading">​</a></h5><ul><li><strong>Width</strong> and <strong>Height</strong> set the resolution of the image.</li></ul><div class="theme-admonition theme-admonition-note alert alert--secondary admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>note</div><div class="admonitionContent_S0QG"><p>Because SDXL was trained at 1024x1024, increasing the resolution beyond that often causes visual artifacts to appear, like a face with multiple noses or too many eyes. If you want large images, it&#x27;s often better to generate them at a normal resolution first, and upscale them after.</p></div></div><h5 class="anchor anchorWithStickyNavbar_LWe7" id="advanced-settings">Advanced settings<a class="hash-link" href="#advanced-settings" title="Direct link to heading">​</a></h5><ul><li><strong>Negative prompt</strong> allows you to specify what you <em>don&#x27;t</em> want to see in the image. If you wish to remove or de-emphasize some undesirable feature, e.g. &quot;color&quot;, it is best to include it in the negative prompt rather than as a negation in the regular prompt (e.g. &quot;no color&quot;).</li><li><strong>Prompt strength</strong> controls how strongly the prompt drives the creation. Higer values usually result in more saturated images.</li><li><strong>Sampler</strong> sets the diffusion sampler to use. See <a href="https://huggingface.co/docs/diffusers/v0.20.0/en/api/schedulers/overview" target="_blank" rel="noopener noreferrer">here for an explanation</a>.</li><li><strong>Steps</strong> sets the number of denoising steps during diffusion. A higher step count may produce better details but is slower. There are strong diminishing returns past 30 steps.</li><li><strong>Seed</strong> sets the random seed for reproducibility. Fixing the seed can make it easier to determine the precise effect of a certain parameter while keeping everything else fixed.</li></ul><h4 class="anchor anchorWithStickyNavbar_LWe7" id="starting-image">Starting Image<a class="hash-link" href="#starting-image" title="Direct link to heading">​</a></h4><p>Instead of generating an image purely from a prompt, you can also use an uploaded image as a starting point for the creation. The starting image will constrain the final creation to resemble the shape and form of the starting image.</p><ul><li><strong>Starting image strength</strong> controls how heavily the starting image influences the final creation. A medium strength to try is around 0.2. Values above 0.5 will look almost identical to your init image, while setting it to 0 is equivalent to having no starting image.</li><li><strong>Adopt aspect ratio of starting image</strong> will adjust the width and height of the creation to match the aspect ratio of the starting image, while keeping the same number of pixels.</li></ul><p align="center"><img src="https://storage.googleapis.com/public-assets-xander/A_workbox/eden_docs/init_img.jpg" alt="An example of create with a starting image. Starting image on the left, resulting creation on the right."><br><small style="color:gray">An example of create with a starting image. Starting image on the left, resulting creation on the right.</small></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="remix">/remix<a class="hash-link" href="#remix" title="Direct link to heading">​</a></h3><p>The remix endpoint takes an input image and creates variations of it. Internally, it does so by using a combination of <a href="https://ip-adapter.github.io/" target="_blank" rel="noopener noreferrer">IP adapter</a> and a technique to construct a prompt that matches your image.</p><p align="center"><img src="/img/generators/remix.jpg" alt="An example of remix. The top left image is the input, the top right image is a remix without a prompt, and the bottom two images are remixes with prompts."><br><small style="color:gray">An example of remix. The top left image is the input, the top right image is a remix without a prompt, and the bottom two images are remixes with prompts.</small></p><p>In remix, the <strong>Starting image</strong> is the input image to be remixed. Like <a href="#create">/create</a>, remix allows you to request 1, 2, or 4 different samples, and inherits all the same basic and advanced settings as create, including <strong>Width</strong>, <strong>Height</strong>, <strong>Negative prompt</strong>, <strong>Guidance scale</strong>, <strong>Sampler</strong>, <strong>Steps</strong>, and <strong>Seed</strong>. However, the following additional settings are specific to the remix endpoint:</p><ul><li><strong>Image strength</strong> controls how much influence the starting image has over the final result. Setting this to 0.0 will try to fully regenerate the content of the starting image but ignore its shape, colors, and composition. Increasing this will produce results which more closely resemble the starting image.</li><li><strong>Remix prompt</strong> allows you to guide the remix generation towards an optional prompt. If left blank, the remix will be entirely guided by the input image.</li><li><strong>Image prompt strength</strong> controls the relative influence between the input image and the Remix prompt (if set). Setting this to 0.0 will produce a remix that is entirely guided by the prompt, while setting it to 1.0 will produce a remix that is entirely guided by the starting image.</li><li><strong>Upscale Factor</strong> upscales the output resolution of your generated image by the given factor. If you want large images, upscaling is generally better than rendering at a higher starting resolution, which can result in repeating artifacts.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="blend">/blend<a class="hash-link" href="#blend" title="Direct link to heading">​</a></h3><p>The blend endpoint is similar to <a href="#remix">/remix</a>, but takes two input images rather than just one and creates an image which combines or mixes the two inputs in a novel way. Like remix, it also relies on <a href="https://ip-adapter.github.io/" target="_blank" rel="noopener noreferrer">IP adapter</a> and prompt reconstruction to match each image, but then averages the internal conditioning of each input image to produce a new image.</p><p align="center"><img src="/img/generators/blend.jpg" alt="Two examples of blend. The left two images are blended to create the right image."><br><small style="color:gray">Two examples of blend. The left two images are blended to create the right image.</small></p><p>In blend, <strong>Your images</strong> lets you upload two starting images. /blend inherits all the same basic and advanced settings as <a href="#remix">/remix</a>, including <strong>Width</strong>, <strong>Height</strong>, <strong>Negative prompt</strong>, <strong>Guidance scale</strong>, <strong>Sampler</strong>, and <strong>Steps</strong>. The following additional settings are specific to the blend endpoint:</p><ul><li><strong>Override prompts</strong> allow you to optionally use a custom prompt for each input image rather than rely on the generator to reconstruct it.</li><li><strong>Interpolation seeds</strong> let you optionally specify the random seed for each input image. This can be useful for reproducibility.</li><li><strong>Image strengths</strong> sets the strength of each image during blending. Low values will give the blend more freedom, higher values will look more like alpha-blending of the original images. Recommended values are 0.0 - 0.1.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="controlnet">/controlnet<a class="hash-link" href="#controlnet" title="Direct link to heading">​</a></h3><p><a href="https://arxiv.org/abs/2302.05543" target="_blank" rel="noopener noreferrer">Controlnet</a> is a versatile technique for guiding image generations with a spatial conditioning map from a control image. The controlnet endpoint in Eden has various capabilities, such as:</p><ul><li>prompt-guided style transfer which conforms to the shape and contours of the control image.</li><li>Generating prompt-guided images which have the same perceived depth or luminosity maps as the control image.</li></ul><p>It is distinct from using a starting image in /create by attempting to reconstruct a specific conditioning signal from the control image, rather than simply using it as the starting image.</p><p align="center"><img src="/img/generators/controlnet.jpg" alt="An example of canny-edge controlnet images driven by the Eden logo. The leftmost image (the Eden logo) is the control image, the four images to the right are output images given different prompts."><br><small style="color:gray">An example of canny-edge controlnet images driven by the Eden logo. The leftmost image (the Eden logo) is the control image, the four images to the right are output images given different prompts.</small></p><p>The following parameters are specific to the controlnet endpoint:</p><ul><li><strong>Shape guidance image</strong> this is the control image which spatially guides the final creation.</li><li><strong>Prompt</strong> has the same function as in the <a href="#create">/create</a>.</li><li><strong>Shape guidance image strength</strong> sets the influence of the shape guidance. This should usually be above 0.5.</li><li><strong>Controlnet mode</strong> sets what to use as conditioning signal:<ul><li>&quot;canny-edge&quot; will try to produce a creation that has the same edges and lines as the control image</li><li>&quot;depth&quot; will try to produce a creation that has the same perceived sense of depth as the control image</li><li>&quot;luminance&quot; will try to mimic the bright and dark regions in your control image</li></ul></li></ul><p>It also inherits the same <strong>Width</strong>, <strong>Height</strong>, <strong>Negative prompt</strong>, <strong>Guidance scale</strong>, <strong>Sampler</strong>, <strong>Steps</strong>, and <strong>Seed</strong> parameters as <a href="#create">/create</a>.</p><p>Controlnet can be a great way to achieve style-transfer on faces as seen in this example:</p><p align="center"><img src="/img/generators/controlnet_style_transfer.jpg" alt="A style transfer of a face using canny-edge controlnet + the prompt &#x27;a statue made of marble&#x27;"><br><small style="color:gray">A style transfer of a face using canny-edge controlnet + the prompt &#x27;a statue made of marble&#x27;</small></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="upscale">/upscale<a class="hash-link" href="#upscale" title="Direct link to heading">​</a></h3><p>Upscale takes a single input image and simply produces an upscaled version of it.</p><p align="center"><img src="/img/generators/upscale.jpg" alt="Upscaling the image on the left"><br><small style="color:gray">Upscaling the image on the left</small></p><p>The only parameters are:</p><ul><li><strong>Init Image</strong> is the input image to be upscaled.</li><li><strong>AI creativity</strong> controls the level of influence of the input image. Lower values (0.2-0.4) result in images that are more similar to the input image. Higher values (0.4-0.7) allow for generated details, but can also deviate more from the input image by inventing new details.</li><li><strong>Width</strong> Maximum width of the final image (/upscale will always maintain aspect ratio).</li><li><strong>Height</strong> Maximum height of the final image (/upscale will always maintain aspect ratio).</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="interpolate">/interpolate<a class="hash-link" href="#interpolate" title="Direct link to heading">​</a></h3><p>Interpolate generates smooth videos which interpolate through a sequence of text prompts. This allows you to create simple, linear video narratives. For example, the following video was created with the prompt sequence:</p><ul><li>a photo of a single lone sprout grows in a barren desert, the horizon is visible in the background</li><li>a photo of a lone sappling growing in a field of mud, realistic water colour</li><li>a photo of a huge, green tree in a forest, the tree is covered in moss</li><li>a photo of an old, crumbled Tree of life, intricate wood folds</li></ul><p align="center"></p><div style="position:relative;padding-bottom:56.25%;height:0;overflow:hidden"><iframe style="position:absolute;top:0;left:0;width:100%;height:100%" src="https://storage.googleapis.com/public-assets-xander/A_workbox/eden_docs/tree_lerp.mp4" title="An interpolation through a prompt sequence." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div><small style="color:gray">An interpolation through a prompt sequence.</small><p></p><p>/interpolate only requires:</p><ul><li><strong>Prompts</strong> an array of prompts to interpolate through.</li></ul><p>Optional settings you may modify regularly include:</p><ul><li><strong>Width</strong> and <strong>Height</strong> set the resolution of the video.</li><li><strong>Frames</strong> sets the number of frames in the video.</li></ul><p>Advanced settings which you may occasionally wish to modify include:</p><ul><li><strong>Loop</strong> will loop the video back to the first prompt after reaching the last prompt.</li><li><strong>Smooth</strong> will apply a smoothing algorithm that reduces large jumps during interpolations. This is recommended.</li><li><strong>FILM Iterations</strong> when set to 1 (recommended), this will double the number of frames using <a href="https://github.com/google-research/frame-interpolation" target="_blank" rel="noopener noreferrer">FILM</a></li><li><strong>FPS</strong> sets the frames per second of the video.</li><li><strong>Interpolation Seeds</strong> sets the random seed for each prompt. This can be useful for reproducibility.</li></ul><p>Additionally, like <a href="#create">/create</a>, /interpolate also inherits <strong>Negative prompt</strong>, <strong>Guidance scale</strong>, <strong>Sampler</strong>, <strong>Steps</strong>, and <strong>Seed</strong>.</p><p>In addition to those parameters, /interpolate also includes a set of three parameters which enable controlnet conditioning to guide the shape of the video, as in the <a href="#controlnet">/controlnet</a> endpoint:</p><ul><li><strong>Shape Guidance Image</strong> sets a control image as a guidance signal throughout the entire video (you must enable one of the controlnet modes).</li><li><strong>Shape guidance image strength</strong> sets the influence of the shape guidance. This should usually be above 0.5.</li><li><strong>Controlnet mode</strong> optionally allows you to use a controlnet conditioning signal. If one is selected, the shape guidance image must also be set.<ul><li>&quot;off&quot; will not use a controlnet</li><li>&quot;canny-edge&quot; will try to produce a creation that has the same edges and lines as the control image</li><li>&quot;depth&quot; will try to produce a creation that has the same perceived sense of depth as the control image</li><li>&quot;luminance&quot; will try to mimic the bright and dark regions in your control image</li></ul></li></ul><p align="center"></p><div style="position:relative;padding-bottom:56.25%;height:0;overflow:hidden"><iframe style="position:absolute;top:0;left:0;width:100%;height:100%" src="https://storage.googleapis.com/public-assets-xander/A_workbox/eden_docs/eden_lerp.mp4" title="An interpolation with the Abraham logo as a controlnet image." frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div><small style="color:gray">An interpolation with the Abraham logo as a controlnet image.</small><p></p><p align="center"></p><div style="position:relative;padding-bottom:56.25%;height:0;overflow:hidden"><iframe style="position:absolute;top:0;left:0;width:100%;height:100%" src="https://www.youtube.com/embed/Bo3VZCjDhGI?si=QlMB3T_aCAx8rrRc" title="An /interpolate video by Xander" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div><small style="color:gray">An /interpolate video by Xander</small><p></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="real2real">/real2real<a class="hash-link" href="#real2real" title="Direct link to heading">​</a></h3><p><strong>Real2Real</strong> generates videos which interpolate through a sequence of uploaded images (called &quot;keyframes&quot;). It is similar to <a href="#interpolate">/interpolate</a>, except that it interpolates through images rather than prompts (although it optionally also allows a sequence of prompts as a secondary guidance signal).</p><p>Real2Real accepts any input image, including photographs, sketches, video frames, images from other generative AI platforms, and so on.</p><p align="center"><img src="https://storage.googleapis.com/public-assets-xander/A_workbox/eden_docs/real2real_input.jpg" alt="/real2real input keyframes"><br><small style="color:gray">/real2real input keyframes</small></p><p align="center"></p><div style="position:relative;padding-bottom:56.25%;height:0;overflow:hidden"><iframe style="position:absolute;top:0;left:0;width:100%;height:100%" src="https://www.youtube.com/embed/5a-hcE8OfQo?si=FOPHay2PBH4dOu9q" title="/real2real output video interpolating through the above keyframes" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe></div><small style="color:gray">/real2real output video interpolating through the above keyframes</small><p></p><p>Real2Real has mostly the same parameters as /interpolate, including <strong>Width</strong>, <strong>Height</strong>, <strong>Frames</strong>, <strong>Loop</strong>, <strong>Smooth</strong>, <strong>FILM Iterations</strong>, <strong>FPS</strong>, <strong>Seeds</strong>, <strong>Negative prompt</strong>, <strong>Guidance scale</strong>, <strong>Sampler</strong>, <strong>Steps</strong>, and <strong>Interpolation Seeds</strong>. It currently lacks compatibility with controlnet. It also includes:</p><ul><li><strong>Override prompts</strong> which allows you to optionally use a custom prompt to optimize towards in addition to each keyframe, similar to <strong>Prompts</strong> in /interpolate.</li><li><strong>Fading smoothness</strong>: low values will result in a rich visual journey, while higher values will look more like alpha-fading but will also be smoother. Values above 0.4 are almost never needed.</li><li><strong>Keyframe strength</strong> is the strength of the keyframes during interpolation. Setting this to 1.0 will exactly reproduce the init imgs at some point in the video, while lower values will allow the video to drift away from your uploaded images.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="txt2vid">/txt2vid<a class="hash-link" href="#txt2vid" title="Direct link to heading">​</a></h3><p>Txt2vid turns a single prompt or a list of prompts into a video animation. This is similar to /interpolate, but uses an actual video generation model, leading to more realistic video output. This endpoint is perfect to visualize narratives driven by prompts. Note that the video model needs enough frames to transition from one prompt to another, so make sure to increase the number of frames if you&#x27;re using many prompts. 24 frames per prompt is a good rule of thumb! Exposed parameters:</p><ul><li><strong>Width</strong>: Width in pixels</li><li><strong>Height</strong>: Height in pixels</li><li><strong>Number of frames</strong> How many frames to render. The final video will be n_frames / 8 seconds.</li><li><strong>Loop</strong>: Whether to generate a seamless loop. If off, the model has a bit more freedom.</li><li><strong>Motion Scale</strong>: How much motion to use. 0.8 is only subtle motion; 1.1 is the default amount of motion; 1.25 is heavy motion and may make the video incoherent.</li></ul><p>Advanced Settings: </p><ul><li><strong>Seed</strong>: as always, the seed can be set for reproducibility</li><li><strong>Negative prompt</strong>: specify what you dont want to see</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="img2vid">/img2vid<a class="hash-link" href="#img2vid" title="Direct link to heading">​</a></h3><p>This is an animation endpoint that takes a single input image and generates an animated video from it. Under the hood this uses <a href="https://github.com/guoyww/AnimateDiff" target="_blank" rel="noopener noreferrer">AnimateDiff</a>. Several input arguments are exposed:</p><ul><li><strong>Width</strong>: Maximum width of the creation (the input aspect ratio will always be maintained)</li><li><strong>Height</strong>: Maximum height of the creation (the input aspect ratio will always be maintained)</li><li><strong>Number of frames</strong> How many frames to render. The final video will be n_frames / 8 seconds.</li><li><strong>Loop</strong>: Whether to generate a seamless loop. If off, the model has a bit more freedom.</li><li><strong>AI Strength</strong>: This is the amount of diffusion done on top of the input image to create the animation. Lowering this value will result in an animation that stays closer to the input image, and exhibits less motion.</li><li><strong>Animation prompt</strong>: This is an optional prompt you can provide which will be used as the motion prompt for AnimateDiff.</li><li><strong>Motion Scale</strong>: How much motion to use. 0.8 is only subtle motion; 1.1 is the default amount of motion; 1.25 is heavy motion and may make the video incoherent.</li></ul><p>Advanced Settings (only change these when you really know what you&#x27;re doing):</p><ul><li><strong>Motion Brush Mask</strong>: Optional Motion Brush mask (only the white regions will be animated)</li><li><strong>Seed</strong>: as always, the seed can be set for reproducibility</li><li><strong>Negative prompt</strong>: specify what you dont want to see.</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="vid2vid">/vid2vid<a class="hash-link" href="#vid2vid" title="Direct link to heading">​</a></h3><p>Vid2vid takes a single input video (mp4, webm, or gif) and one or two style images and tries to recreate the input video in the style of the style image(s). This endpoint may require experimentation to get good results. Some style image / input video combinations work much better than others! Exposed parameters:</p><ul><li><strong>number of frames</strong> How many animation frames to render. The final video length will be n_frames / 8 seconds. This value will automatically get capped when reaching the end of your input video</li><li><strong>shape guidance method</strong>: Set if you want coarse or fine shape guidance form the input video. Coarse usually gives better looking videos, but will ignore more small details from the input video.</li><li><strong>Optional style prompt</strong>: Optional prompt used on top of the style image(s). You can try something like &quot;an animation of <!-- -->[describe your input video]<!-- --> in the style of <!-- -->[describe your style image]<!-- -->&quot;</li><li><strong>Width</strong>: Maximum width of the creation (the input aspect ratio will always be maintained)</li><li><strong>Height</strong>: Maximum height of the creation (the input aspect ratio will always be maintained)</li><li><strong>AI Strength</strong>: How much diffusion to apply to the input video/gif (1.0 = fully reimagine input, 0.0 = return input as is). The default of 0.95 will use a tiny bit of the colors from the input.</li><li><strong>Shape Control Strength</strong>: How much the shape of the input video/gif drives the shape of the result.</li><li><strong>Loop</strong>: This tries to create a seamlessly looping video where end = start. If the input video/GIF does not loop, this might not be a good idea.</li><li><strong>Motion Scale</strong>: How much motion you want to see (1.1 is usually great, 0.8 is only very subtle motion, 1.25 is a LOT of motion and often destroys the video)</li></ul><p>Advanced Settings (only change these when you really know what you&#x27;re doing):</p><ul><li><strong>Seed</strong>: as always, the seed can be set for reproducibility</li><li><strong>Negative prompt</strong>: specify what you dont want to see.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="creating-with-concepts">Creating with concepts<a class="hash-link" href="#creating-with-concepts" title="Direct link to heading">​</a></h2><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_S0QG"><p>To train your own concept, see <a href="/docs/guides/concepts">training concepts</a>.</p></div></div><p>Concepts are custom objects, styles, or specific people which have been trained and added by Eden users to the Eden generators&#x27; knowledge base, using the <a href="https://arxiv.org/abs/2106.09685" target="_blank" rel="noopener noreferrer">LoRA technique</a>. Concepts are available in all the creation endpoints, and work the same way for all of them.</p><p>Concepts are necessary to be able to consistently generate a specific person, style, or object which is not part of the base model&#x27;s knowledge.</p><p>The base model with no concepts is the default model used by all the endpoints. To activate a specific concept, it must first be selected. Clicking &quot;Select Concept&quot; brings up a menu of all available concepts on Eden. Toggle between &quot;All Concepts&quot; and &quot;My Concepts&quot; to filter by either all public concepts or just your own concepts.</p><p align="center"><img src="/img/conceptselector.jpg" alt="Selecting a public concept"><br><small style="color:gray">Selecting a public concept</small></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="composing-with-concepts">Composing with concepts<a class="hash-link" href="#composing-with-concepts" title="Direct link to heading">​</a></h3><p>Once selected, you may optionally compose with that concept by including its name or &quot;concept&quot; in the prompt. Note that the concept is <em>not</em> case-sensitive. For example, if your concept is named <strong>Alice</strong>, then you can reference the concept in any of the equivalent ways.</p><ul><li>A photograph of Alice training a neural network.</li><li>A photograph of alice training a neural network.</li><li>A photograph of &lt;alice<!-- -->&gt;<!-- --> training a neural network.</li><li>A photograph of &lt;Alice<!-- -->&gt;<!-- --> training a neural network.</li><li>A photograph of &lt;concept<!-- -->&gt;<!-- --> training a neural network.</li></ul><div class="theme-admonition theme-admonition-tip alert alert--success admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_S0QG"><p>If the concept was trained in &quot;face&quot; or &quot;object&quot; mode, it is recommended to trigger the concept by referring to it in the prompt. If the concept was trained in &quot;style&quot; mode, the concept will be automatically triggered for you.</p></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="adjusting-concept-strength">Adjusting concept strength<a class="hash-link" href="#adjusting-concept-strength" title="Direct link to heading">​</a></h3><p>The &quot;Concept strength&quot; parameter controls the influence of the concept on the final output. If your creations dont resemble your concept enough you can increase this value, if your prompt is being ignored and everything looks to similar to the training images, try reducing the strength.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2024-02-13T07:19:13.000Z">Feb 13, 2024</time></b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/category/guides"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Guides</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/guides/concepts"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Training Concepts (LoRa)</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#summary-of-endpoints" class="table-of-contents__link toc-highlight">Summary of endpoints</a><ul><li><a href="#create" class="table-of-contents__link toc-highlight">/create</a></li><li><a href="#remix" class="table-of-contents__link toc-highlight">/remix</a></li><li><a href="#blend" class="table-of-contents__link toc-highlight">/blend</a></li><li><a href="#controlnet" class="table-of-contents__link toc-highlight">/controlnet</a></li><li><a href="#upscale" class="table-of-contents__link toc-highlight">/upscale</a></li><li><a href="#interpolate" class="table-of-contents__link toc-highlight">/interpolate</a></li><li><a href="#real2real" class="table-of-contents__link toc-highlight">/real2real</a></li><li><a href="#txt2vid" class="table-of-contents__link toc-highlight">/txt2vid</a></li><li><a href="#img2vid" class="table-of-contents__link toc-highlight">/img2vid</a></li><li><a href="#vid2vid" class="table-of-contents__link toc-highlight">/vid2vid</a></li></ul></li><li><a href="#creating-with-concepts" class="table-of-contents__link toc-highlight">Creating with concepts</a><ul><li><a href="#composing-with-concepts" class="table-of-contents__link toc-highlight">Composing with concepts</a></li><li><a href="#adjusting-concept-strength" class="table-of-contents__link toc-highlight">Adjusting concept strength</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://app.eden.art" target="_blank" rel="noopener noreferrer" class="footer__link-item">App<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/docs/category/overview">Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/4dSYwDT" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/eden_art_" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://instagram.com/eden.art____" target="_blank" rel="noopener noreferrer" class="footer__link-item">Instagram<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Developers</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/github.com/edenartlab" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.npmjs.com/package/@edenlabs/eden-sdk" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eden SDK (JS)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/abraham-ai/eden-sdk-py" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eden SDK (Python)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright"> </div></div></div></footer></div>
<script src="/assets/js/runtime~main.b6bbc6ef.js"></script>
<script src="/assets/js/main.23358c95.js"></script>
</body>
</html>